\subsection{Discussions}

\paragraph{The Haptic-Editing process}

Through our evaluation, we discovered that users generally appreciated shape-driven haptic feedback, as it is salient, easily discriminated, offers practical uses like density estimation, and prevents users from overpopulating terrain regions. We also learned that texture feedback as we implement it in this work is of limited usefulness, as many users complained of poor differentiability. Use of a 2Diy interface to populate a 2D terrain object was grasped intuitively, and none of our participants had difficulty understanding the connection between the physical end effector and the representation of the end effector in our editor. We claim our interface would be well-suited as a plugin to Unity, allowing game developers to continue using tools they're familiar with, but with the added benefit of haptic feedback for terrain editing and similar applications. Indeed, force and texture feedback are both driven by parts of the engine, colliders and normal maps respectively, that will necessarily be used by a game developer in this context, and thus our interface requires no additional burden to use. 

\paragraph{Unity as a tool for haptics design}

Throughout history, various art forms, such as music, drawing, photography, film, video editing, game development, and XR development, have experienced significant advancements whenever developers have embraced user-friendly tools. These advancements have been facilitated by the availability of accessible cameras, freely available software for music composition and video editing, as well as widely supported game engines like Unity and Unreal. However, when the primary means of entry into these fields is limited to Java and Processing code, the potential for designing experiences becomes constrained by the technical skills of developers, creating a bottleneck effect. It is imperative to encourage the haptics community to explore beyond mere code frameworks and instead adopt a singular, user-friendly engine (such as Unity) that can empower designers to focus on the user experience aspect of haptics, rather than being bogged down by technical jargon. Such an approach would enable individuals to specialize in various aspects of haptics, be it hardware, software, or design, akin to the specialization seen in the game development industry, thereby enhancing the overall quality of output.

\subsection{Limitations}

\paragraph{Movement in an infinite space}

With our current implementation, the end effector can only move in the virtual space a distance proportional to the Haply device's arm length. While we can change the movement scale in the engine, the end effector will eventually get stuck due to the haply 2DIY's limited range of motion. The primary difficulty lies in changing the relative positioning of the proxy with respect to the world, and what the underlying user experience design philosophy should be for the same without disorienting the user.

\paragraph{Fine grain control of placed objects}
While we have the ability to place objects around a specific space, we do not have the ability to move or rotate a placed object in any degree of freedom, or scale the object up and down. This was an initial consideration our project had but had to be discarded in the interest of time and producing a working prototype. The main issue with this comes in tackling the user interaction model to edit the transform data of an object. Since the haply is the main mode of interaction, we could consider using it similar to a mouse, and designing movement, rotation and scale gizmos that can subsequently be used for the editing process.
