\paragraph{Image-based Haptic Texture Rendering}
\citet{li2010image} produce a method for extracting normal forces from 2D images, which may then be rendered by a 3D haptic interface. The paper distinguishes between normal forces, acting in the vertical axis, and tangential forces, acting in the surface plane. In our work, we render these tangential forces and forego normal forces due to our use of a 2 DOF haptic device. We do not introduce a method for \textit{creating} normal maps for our application, but instead reference the work of \citet{li2010image} as an example of how one may extract normal information from image textures. \citet{li2010image} display high rates of differentiability between represented textures with their method, though textures used in their evaluation are contrived and not based on real-world images.

\paragraph{Haptic Perception of Material Properties and Implications for Applications}
\citet{klatzky2013haptic} offer an overview of state-of-the-art approaches to haptic rendering of material properties. We bring attention to the discussion on texture representation, and note we use a normal mapping approach which allows for both direction and magnitude control of surface normals, forming a modified single-point probe model. \citet{klatzky2013haptic} also note roughness and texture discrimination as a common evaluation metric for applications targeting textural rendering.

\paragraph{Hand Movements: A Window into Haptic Object Recognition}
\citet{LEDERMAN1987342} catalogs exploratory techniques used when exploring physical objects. Our interface affords the patterns of lateral motion, static contact, pressure and contour folding, mediated through the single-point probe interface offered by our 2 DOF device. We note that these affordances were deemed by \citet{LEDERMAN1987342} to be sufficient (in that they allow performance better than chance) for texture and exact shape differentiation.
